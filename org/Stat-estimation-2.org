#+setupfile: info/index-bigblow-header.setup
#+include: info/common-header.org
#+AUTHOR: 鈴木正幸，非常勤講師
#+title: 確率と統計 8.点推定
#+OPTIONS: tex:t
#+property: header-arg:R :session *rfors* :results output :exports both :width 400 :height 300

* 8.1 推定量 \( T(\vec{X}) \)

  - 推定量 \( T(\vec{X}) \) :: 母集団のパラメーターを推定するための，統計量
   (確率変数の計算式)

  - 点推定 :: \( T(\vec{X}) \) の標本値 \( T(\vec{x}) \)を計算し， 母集団のパラメーター
    を推定すること

  - \( \hat{\theta} \) :: パラメーター \( \theta \) の点推定値
    
** 不偏性

   - \( E[T(\vec{X})] = \theta \) :: 推定量の平均が母パラメーターにな
     ること

     
** 一致性

   - \( T(\vec{X}) \stackrel{P}{\longrightarrow} \theta \) :: 標本
     サイズが大きければ，推定量は母パラメーターに確率収束すること

* 8.2 推定量の作り方 (モーメント法)
  
** \( \mu  = E[X] \) の推定

   \( \hat{\mu} = \overline{X} = \frac{1}{n}\Sigma_1^{n} X_i \)

   - 不偏であり，一致である

** \( \tau  = E[X^2] \) の推定
   
   \( \hat{\tau} = \overline{X^2} = \frac{1}{n}\Sigma_1^{n} X_i^2 \)

   - 不偏であり，一致である
	
** \( \sigma^2 = E[(X-\mu)^2] \) の推定

   \( \mu \) が既知ならば \( \hat{\sigma}^2 = \frac{1}{n}\Sigma_1^{n}    (X_i-\mu) ^2 \)

   \( \mu \) が未知ならば, \( \mu \) の推定量 \( \overline{X} \) を使
   い，
   \( \hat{\sigma}^2 = \frac{1}{n}\Sigma_1^{n}    (X_i- \overline{X})
   ^2 \)

   これは不偏推定量ではないため，
   
   \( \hat{\sigma}^2 = \frac{1}{(n-1)}\Sigma_1^{n}    (X_i- \overline{X})
   ^2 = S^2 \)

   - 不偏であり，一致である
   
** \( \sigma_{xy} = E[(X-\mu_x)(Y-\mu_y)] \) の推定

   \( \hat{\sigma}_{xy} = \frac{1}{(n-1)} \Sigma_1^n (X_i-\overline{X})
   (Y_i - \overline{Y}) = S_{xy} \)

   - 不偏であり一致である
   
** 相関係数 \( \rho_{xy} = \sigma_{xy} /\sqrt{\sigma^2_x \sigma^2_y} \) の推定

   \( \rho_{xy} = S_{xy} /\sqrt{S^2_x / S^2_y} \) を用いる。

   - 一致であるが不偏ではない
   
* 8.3 推定量の良さ (平均2乗誤差の小ささ)

  - パラメータ \( \theta \) の推定量 \( T = T(\vec{X}) \)

  - 平均2乗誤差 ::  \( \theta \) と \( T \) の乖離を \(E[(\theta-T)^2]
    \) で測る

    平均2乗誤差が小さいほど良い。

  - 平均2乗誤差 = 分散 + バイアス

    \begin{eqnarray}
    E[(\theta-T)^2] & = & E[\{(T-E[T])+(E[T]-\theta)\}^2] \\
    & = & E[{(T-E[T])^2+(E[T]-\theta)^2+2(T-E[T])(E[T]-\theta)}]\\
    & = & E[(T-E[T])^2] + (E[T]-\theta)^2\\
    & = & V[T] + (E[T]-\theta)^2\\
    \end{eqnarray}

    

* 8.4 最尤推定

  パラメータ \(\vec{\theta}\) を含む，確率密度関数を，\(f(\vec{x};
  \vec{\theta})\) と書くことにする。
  
** 尤度

   \(\vec{x}\) の値を\(\vec{w}\)とする。(確率変数 \( \vec{X} \) の標本
   値が \(\vec{w}\))

   \( f(\vec{w}; \theta) \) を尤度または尤度関数と呼ぶ

   \( f(\vec{X}; \theta) \) も尤度または尤度関数と呼ぶ
   
** 最尤推定
   
*** 離散型

    \( P(\vec{X} = \vec{x} ) = f(\vec{x}, \theta) = L(\theta; \vec{x})
    \)

    \(\vec{x}\)は標本値。その値の時の同時確率密度関数値つまり尤度が最
    大だったため，\(\vec{x}\)が観測されたのだ，と考える。

    \( \hat{\theta} = \hat{\theta}(\vec{x}) = \rm{argmax}_{\theta}f(\vec{x},
    \theta) = \rm{argmax}_{\theta}L(\theta; \vec{x})\)

    - f の 最大値を与える，\( \theta \) 探すということ
    - [[https://ja.wikipedia.org/wiki/Arg_max][arg max - Wikipedia]]

*** 対数尤度

    - 対数尤度 :: \( L(\theta;\vec{x}) \) の対数

      \( l(\theta; \vec{x}) = \log L(\theta; \vec{x}) = \log f(\theta;    \vec{x}) \)

      - log を取っても関数の増減傾向は同じ，
      - 積を和の形にし，微分し易くする

      - 対数尤度関数の \(\theta\) に関する最大値を探す

	- 尤度方程式 \( \rm{d} l(\theta; \vec{x})/ \rm{d}\theta = 0\) で
          極値を探す

      - 無作為標本 \( X_{i=1:n} \) であれば，

	- \( f(\vec{x}, \theta)  = \Pi_{i=1}^{n} f_i(x_i; \theta) \) で
          あるので，

	- \( \hat{\theta } = \rm{argmax}_{\theta} \Sigma_{i=1}^{n}
          l(\theta; x_i) \) となり，微分し易くなる
	  
** 例
   
*** ベルヌーイ分布

*** ポアソン分布

*** 正規分布

    - 対数尤度関数を，\( \mu \) と \( \sigma^2 \) の二つのパラメーターに
      かんする最大値を求める

      - \( \mu \) に関しては，\( \overline{x} = \mu \) で，最大がわか
        る

      - \( \sigma^2 \) に関しては，\( -\frac{n}{2} \log \sigma^2
        -\frac{1}{2\sigma^2}\Sigma(x_i-\overline{x})^2 \)
	を \( \sigma^2 \) で微分し，

	\( \frac{-1}{\sigma^2}\left(n -
        \frac{1}{\sigma^2}\Sigma(x_i-\overline{x}) \right) = 0 \) ，

	\(\sigma^2 = \frac{1}{n}\Sigma(x_i-\overline{x})^2 \)となる。

	標本不偏分散ではなく，標本分散となる。




* 8.5 例

  手書ノートで説明します。
  
** 8.5.1 職場環境満足度アンケート

   個人の満足度を知られないアンケートの実施方法

   - サイコロを振り，1と2の目がでた時は，本当の気持を答え
   - それ以外の目の時は，反対の気持を答える
     
*** 設定

    - \( X \) : 1が満足，0が不満
    - \( Y \) : 1が1と2の出目，0がそれ以外
    - \( Z \) : 1が満足と答える， 0 が不満と答える
      
    - 満足度のパラメータ \( \theta = P (X=1) \)
    - \( P(Y=1) = 1/3 = \alpha \)
    - \( X \)と \( Y \) は，独立
      
    - \( Z_{i=1:n} \)，\( \overline{Z_{(n)}} \) は \( \theta \) の妥当
      な推定量ではない

*** 「満足」と答える確率 \( \eta = P(Z=1) \)

    |------------+-----------------------+---------------------|
    |            | \( Y=1 \), 本当を言う | \( Y=0 \), 嘘を言う |
    | \( X= 1 \) | \(Z = 1 \)            | \( Z = 0 \)         |
    | \( X= 0 \) | \(Z = 0 \)            | \( Z = 1 \)         |
    |------------+-----------------------+---------------------|

    \( \eta = P(Z=1) \) = \( P(X=1, Y=1) + P(X=0, Y=0) \)

    \( = P(X=1) P(Y=1) + P(X=0) P(Y=0) \)

    \( = \theta \alpha + (1-\theta)(1-\alpha) \)

    \( = (2\alpha -1)\theta + (1-\alpha) \)

    \( \overline{Z_{(n)}} \) は \( \eta \) の妥当な推定量。

    なので，\(\hat{\eta} = \overline{Z_{(n)}} =  (2\alpha -1)\theta + (1-\alpha) \)

    \( \hat{\theta} = \frac{\overline{Z_{(n)}}}{2\alpha-1}\)


    #+begin_src R :session *stext* :results output :exports both
##
## 教科書 8.5.1 アンケート
##
est_theta <- function (enq, alpha) {
  (mean(enq)-(1-alpha))/(2*alpha-1)
}

size <- 1000
honest_p <- 1/3
satisfied_p <- 6/10

honest <- rep(0,size)
honest [(runif(size,0,1))>(1-honest_p)] <- 1
table(dice)

satisfied <- rep(0,size)
satisfied [(runif(size,0,1))>(1-satisfied_p)] <- 1

table(satisfied)
enq <- rep(0,size)
for (i in 1:size) {
    res <- 0
    if (honest[i]==satisfied[i]) { res <- 1 }
    enq[i] <- res
}

mean(honest)
mean(satisfied)
mean(enq)
est_theta(enq, honest_p)
    #+end_src

    #+RESULTS:
    #+begin_example
    dice
      0   1 
    354 646
    satisfied
      0   1 
    439 561
    [1] 0.309
    [1] 0.561
    [1] 0.514
    [1] 0.458
    #+end_example


** 8.5.2 どちらの面積推定が優れているか
   
*** 長方形の面積を測る問題

    - \( \mu_{x, y} \) :: 縦と横の長さ
    - \( S = \mu_x \mu_y \) :: 面積の計算
    - \( (X_i, Y_i)_{i=1:n} \) :: 計測

    - A案 :: \( S_A = \Sigma_{1}^{n} X_i Y_i / n \)
    - B案 :: \( S_B = \overline{X} \times \overline{Y} \)
      
*** 二つの案の比較のための設定
    - 縦横の長さの母集団 \( (X, Y) \)
    - \( X \sim (\mu_x, \sigma_x^2) \), \( Y \sim (\mu_y, \sigma_y^2)
      \)
    - \( (X_i, Y_i)_{i=1:n} \) は無作為標本
    - \( S_A \), \( S_B \) を平均二乗誤差で測る
      
*** \( Z = X Y \) 

**** 期待値

      \( E[Z] = E[XY] = E[X] E[Y] = \mu_x \mu_y = S\)

      \( S_A = \frac{1}{n}\Sigma_{1}^{n} X_i Y_i =
      \frac{1}{n}\Sigma_{1}^{n} Z_i =  \overline{Z} \)

      従って，\( S_A \) は面積 \( S = E[Z] \) の不偏推定量

**** \( Z = X Y \) の分散

     \begin{eqnarray}
     V[Z] & = & E[(Z-S)^2] \\
     & = & E[Z^2] - S^2 \\
     & = & E[X^2Y^2] - \mu_x^2 \mu_y^2 \\
     & = & E[X^2]E[Y^2] - \mu_x^2 \mu_y^2 \\
     & = & (\mu_x^2+\sigma_x^2)(\mu_y^2+\sigma_y^2) - \mu_x^2 \mu_y^2
     \\
     & = & \mu_x^2\sigma_x^2 + \mu_y^2\sigma_y^2 + \sigma_x^2 \sigma_y^2
     \\
     \end{eqnarray}
    \( S_A \) の平均二乗誤差は，

    \begin{eqnarray}
    E[(S_A-S)^2] &= & E[(\overline{Z}-E[Z])^2] \\
    & = & \frac{1}{n} V[Z] \\
    & = & \frac{1}{n} (\mu_x^2\sigma_y^2 + \mu_y^2\sigma_x^2 +
    \sigma_x^2 \sigma_y^2) \\
    \end{eqnarray}
     
     
     
*** \(Z^* = \overline{X} \overline{Y} \)

    \( S_B = Z^* \) となる
    
**** 期待値

     \( E[S_B] = E[Z^*] = E[\overline{X} \overline{Y}] =
     E[\overline{X}]E[\overline{Y}] = \mu_x \mu_y = S
     \)


**** 分散
     
     \( \overline{X} \) の分散は \( \sigma_x^2/n \),
     \( \overline{Y} \) の分散は \( \sigma_y^2/n \)
     
     \( S_B \) の平均二乗誤差

     \begin{eqnarray}
     E[(S_B-S)^2] &= & E[(Z^*-E[Z^*])^2] \\
     & = & V[Z^*] \\
     & = & \mu_x^2\frac{\sigma_y^2}{n} + \mu_y^2 \frac{\sigma_x^2}{n} +
     \frac{\sigma_x^2}{n}\frac{\sigma_y^2}{n} \\
     & = & \frac{1}{n} (\mu_x^2\sigma_y^2 + \mu_y^2\sigma_x^2 + \frac{1}{n}
     \sigma_x^2 \sigma_y^2) \\
     \end{eqnarray}
     
*** 結論

    \( E[(S_A - S)^2] - E[(S_B - S)^2] = \frac{n-1}{n} \sigma_x^2
    \sigma_y^2  \geq 0 \)
    
** 8.5.3 Rによる最尤法の計算例
   [[file:misc/mle.org::*optim による最尤推定 (2変数)][optim による最尤推定 (2変数)]]
